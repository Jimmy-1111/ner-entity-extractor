import streamlit as st
import pandas as pd
from transformers import pipeline

@st.cache_resource
def load_ner_pipeline():
    return pipeline(
        "ner", 
        model="ku-nlp/roberta-base-japanese-ner", 
        aggregation_strategy="simple"
    )

def extract_entities(text, ner):
    if not isinstance(text, str) or not text.strip():
        return "ï¼ˆç„¡ï¼‰"
    try:
        entities = ner(text)
        if not entities:
            return "ï¼ˆç„¡ï¼‰"
        return "ã€".join(f"{e['word']}({e['entity_group']})" for e in entities)
    except Exception as e:
        return "ï¼ˆç„¡ï¼‰"

st.title("ğŸš€ æ—¥æ–‡ BERT NER Streamlit å·¥å…·")

uploaded_file = st.file_uploader("è«‹ä¸Šå‚³è¦åˆ†æçš„ Excel æª”æ¡ˆï¼ˆå«å¥å­å…§å®¹ï¼‰", type=["xlsx"])

if uploaded_file:
    df = pd.read_excel(uploaded_file)
    # è®“ä½¿ç”¨è€…é¸æ“‡èªå¥å…§å®¹æ¬„ä½
    column_name = st.selectbox("é¸æ“‡å¥å­å…§å®¹çš„æ¬„ä½", options=df.columns, index=0)
    if st.button("é–‹å§‹è¾¨è­˜å¯¦é«”"):
        with st.spinner("è¼‰å…¥æ¨¡å‹èˆ‡åˆ†æä¸­ï¼Œè«‹ç¨å€™ï¼ˆé¦–æ¬¡ä¸‹è¼‰æœƒè¼ƒä¹…ï¼‰..."):
            ner = load_ner_pipeline()
            df["NERå°ˆæœ‰åè©"] = df[column_name].apply(lambda x: extract_entities(x, ner))
        st.success("è¾¨è­˜å®Œæˆï¼")
        st.write(df[["NERå°ˆæœ‰åè©"] + [column_name]].head(20))  # é è¦½å‰20ç­†
        # ä¸‹è¼‰çµæœ
        out = df.to_excel(index=False)
        st.download_button("ğŸ“¥ ä¸‹è¼‰å…¨éƒ¨è¾¨è­˜çµæœ Excel", out, file_name="ner_çµæœ.xlsx")

st.info("æœ¬å·¥å…·ä½¿ç”¨ BERT NER æŠ½å–æ—¥æ–‡å°ˆæœ‰åè©ï¼Œæ¨è–¦æœ¬åœ°åŸ·è¡Œï¼ˆé¦–æ¬¡åŸ·è¡Œéœ€ä¸‹è¼‰æ¨¡å‹ï¼Œè«‹è€å¿ƒç­‰å€™ï¼‰ã€‚")
