import streamlit as st
import pandas as pd
import io
from janome.tokenizer import Tokenizer

# ==== Stopwords å®¢è£½ ====
STOPWORDS = set([
    "ã“ã¨", "ãŸã‚", "ã‚‚ã®", "ã‚ˆã†", "ã¨ã“ã‚", "ã“ã‚Œ", "ãã‚Œ", "ã‚ã‚Œ",
    "ã®", "ã«", "ã¯", "ãŒ", "ã‚’", "ã¨", "ã§", "ã‚‚", "ã¸", "ã‹ã‚‰", "ã¾ã§",
    "åŠã³", "ã‚ˆã‚Š", "ã¨ã—ã¦", "ã«ã¤ã„ã¦", "ãªã©", "ã«ãŠã‘ã‚‹", "ã«ã‚ˆã‚Š", "ä¸€æ–¹", "ã¾ãŸ", "ã•ã‚‰ã«", "ãªãŠ", "å½“é¢", "ã¾ãš", "æ¬¡ã«", "ãŠã‚ˆã³"
])

# ==== åè©æŠ½å–å‡½æ•¸ ====
janome_tokenizer = Tokenizer()

def extract_nouns(text):
    tokens = janome_tokenizer.tokenize(text)
    nouns = [t.surface for t in tokens if t.part_of_speech.split(',')[0] == "åè©"]
    nouns = [w for w in nouns if w not in STOPWORDS and len(w) > 1]
    return nouns

# ==== Streamlit App ====
st.title("ğŸ“‹ æ—¥æ–‡æ¯å¥å…¨åè©æŠ½å–å·¥å…·ï¼ˆå·²æ’é™¤ stopwordsï¼‰")
uploaded = st.file_uploader("è«‹ä¸Šå‚³ Excelï¼ˆéœ€æœ‰ã€èªå¥å…§å®¹ã€æ¬„ï¼‰", type=["xlsx"])

if uploaded:
    df = pd.read_excel(uploaded)
    if "èªå¥å…§å®¹" not in df.columns:
        st.error("ç¼ºå°‘ã€èªå¥å…§å®¹ã€æ¬„ä½")
        st.stop()
    sentences = df["èªå¥å…§å®¹"].astype(str).tolist()
    all_nouns = []
    for sent in sentences:
        nouns = extract_nouns(sent)
        all_nouns.append("ã€".join(sorted(set(nouns))) if nouns else "ï¼ˆç„¡ï¼‰")
    df["å¥å…§åè©"] = all_nouns
    st.dataframe(df)
    output = io.BytesIO()
    df.to_excel(output, index=False)
    st.download_button("ğŸ“¥ ä¸‹è¼‰åè©çµæœ", data=output.getvalue(), file_name="æ¯å¥åè©çµæœ.xlsx")
